//! @file ArcsNeuron.hh
//! @brief 深層学習クラス
//!
//! 深層学習クラス（試作実装中）
//!
//! @date 2025/12/31
//! @author Yokokura, Yuki
//
// Copyright (C) 2011-2025 Yokokura, Yuki
// MIT License. For details, see the LICENSE file.

#ifndef ARCSNEURON
#define ARCSNEURON

#include <cassert>
#include <array>
#include <functional>
#include <any>

// ARCS組込み用マクロ
#ifdef ARCS_IN
	// ARCSに組み込まれる場合
	#include "ARCSassert.hh"
	#include "ARCSeventlog.hh"
#else
	// ARCSに組み込まれない場合
	#define arcs_assert(a) (assert(a))
	#define PassedLog()
	#define EventLog(a)
	#define EventLogVar(a)
#endif

#include "ArcsMatrix.hh"

namespace ARCS {	// ARCS名前空間

template <typename T> class ArcsNeu;	// 前方宣言

// ArcsNeuronメタ関数定義
namespace ArcsNeuron {
	// 整数・実数型チェック用メタ関数
	template<typename T> struct IsIntFloatV {
		static constexpr bool value = std::is_integral<T>::value | std::is_floating_point<T>::value;
	};
	template<typename T> inline constexpr bool IsIntFloat = IsIntFloatV<T>::value;
}

// ArcsNeuron名前空間
namespace ArcsNeuron {
	//! @brief 自動微分演算の定義
	enum class AutoDiffOperator {
		ANE_NONE,	//!< 無し
		ANE_ADD,	//!< 加算
		ANE_MULT,	//!< 乗算
		ANE_RELU,	//!< ReLU活性化関数
	};
	
	//! @brief 自動微分スタックデータ定義
	//! @tparam	T	深層学習データ型
	template <typename T = double>
	struct AutoDiffData {
		AutoDiffOperator ForwardOperator;	//!< 順方向演算の種類
		std::function<void(const ArcsNeu<T>*, ArcsNeu<T>*, ArcsNeu<T>*)> BackOperator;	//!< 逆方向用演算への関数オブジェクト
		ArcsNeu<T>* u1;	//!< 入力エッジ変数1への生ポインタ
		ArcsNeu<T>* u2;	//!< 入力エッジ変数2への生ポインタ
		ArcsNeu<T>* y;	//!< 出力エッジ変数への生ポインタ
	};
}

//! @brief 自動微分スタックメモリ(勾配テープ)
//! @tparam	T	深層学習データ型
template <typename T = double>
class ArcsNeuStack {
	public:
		//! @brief コンストラクタ
		constexpr ArcsNeuStack() noexcept
			: Stack({}), StackCounter(0), TempObjStack({}), TempObjStackCounter(0)
		{
			// 自動微分スタックの初期化
			for(size_t i = 0; i < MAX_OPERATION; ++i){
				Stack.at(i).ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_NONE;
				Stack.at(i).BackOperator = nullptr;
				Stack.at(i).u1 = nullptr;
				Stack.at(i).u2 = nullptr;
				Stack.at(i).y  = nullptr;
			}

			// 一時オブジェクトスタックの初期化
			for(size_t i = 0; i < MAX_TEMPOBJ; ++i){
				TempObjStack.at(i).SetAutoDiffStack(this);
			}
		}

		//! @brief ムーブコンストラクタ
		//! @param[in]	r	演算子右側
		constexpr ArcsNeuStack(ArcsNeuStack&& r) noexcept
			: Stack({}), StackCounter(0), TempObjStack({}), TempObjStackCounter(0)
		{
			
		}

		//! @brief ムーブ代入演算子
		//! @param[in]	r	演算子右側
		constexpr ArcsNeuStack& operator=(ArcsNeuStack&& r) noexcept {
			return *this;
		}
		
		//! @brief デストラクタ
		~ArcsNeuStack() noexcept {
			
		}
		
		//! @brief 自動微分スタックに演算履歴データを積む関数
		//!	@param[in]	ad	自動微分データ
		//! @return	自動微分スタック内の出力エッジ変数への生ポインタのアドレス
		constexpr ArcsNeu<T>** Push(const ArcsNeuron::AutoDiffData<T>& ad){
			Stack.at(StackCounter) = ad;
			StackCounter++;
			return &(Stack.at(StackCounter - 1).y);
		}

		//! @brief 一時オブジェクトスタックに永続化したオブジェクトエッジ変数を積む関数
		//!	@param[in]	tempobj	一時オブジェクト
		//! @return	一時オブジェクトスタック内のエッジ変数への生ポインタのアドレス
		constexpr ArcsNeu<T>* Persistent(ArcsNeu<T> tempobj){
			TempObjStack.at(TempObjStackCounter) = tempobj;	// コピーして一時オブジェクトエッジ変数を永続化
			TempObjStackCounter++;
			return &(TempObjStack.at(TempObjStackCounter - 1));
		}

		//! @brief 自動微分スタックに積まれた演算履歴を逆に辿って勾配を計算する関数
		constexpr void UpdateGradient(void){
			for(ssize_t i = StackCounter - 1; 0 <= i; --i){
				Stack.at(i).BackOperator(Stack.at(i).y, Stack.at(i).u1, Stack.at(i).u2);
			}
		}

		//! @brief 自動微分スタックに積まれたエッジ変数の勾配をクリアする関数
		constexpr void ClearGradient(void){
			for(ssize_t i = StackCounter - 1; 0 <= i; --i){
				Stack.at(i).y->ClearGradient();
				Stack.at(i).u1->ClearGradient();
				if(Stack.at(i).u2 != nullptr) Stack.at(i).u2->ClearGradient();	// 活性化関数の場合は nullptr なので回避
			}
		}

		//! @brief 自動微分スタックに積まれた演算履歴を表示する関数
		void DispStack(void) const{
			printf("<ADSM - Auto Differential Stack Memory>\n");
			for(size_t i = 0; i < StackCounter; ++i){
				printf("%5zu: %p %s %p -> [%p] %p\n", i, Stack.at(i).u1, GetOperatorName(i).c_str(), Stack.at(i).u2, &(Stack.at(i).y), Stack.at(i).y);
			}
		}

		//! @brief 一時オブジェクトスタックに積まれた永続化オブジェクト履歴を表示する関数
		void DispTempObjStack(void) const{
			printf("<TOSM - Temporary Object Stack Memory>\n");
			for(size_t i = 0; i < TempObjStackCounter; ++i){
				printf("%5zu: [%p]\n", i, &(TempObjStack.at(i)));
			}
		}

		//! @brief 一時オブジェクトスタックに積まれた永続化オブジェクトエッジ変数値を表示する関数
		void DispTempObjVar(void) const{
			printf("<TOSM Edge Variables>\n");
			for(size_t i = 0; i < TempObjStackCounter; ++i){
				printf("%5zu", i);
				TempObjStack.at(i).Disp();
			}
		}

		//! @brief 逆方向計算の過程を表示する関数
		constexpr void DispBackwardCalc(void){
			printf("<Backward Calculation>\n");
			for(ssize_t i = StackCounter - 1; 0 <= i; --i){
				printf("%5zu: %p -(%s)-> %p, %p \n", i, Stack.at(i).y, GetOperatorName(i).c_str(), Stack.at(i).u1, Stack.at(i).u2);
			}
		}

		//! @brief 演算の文字列での名前を得る関数
		//! @return	演算名
		std::string GetOperatorName(const size_t Index) const{
			switch(Stack.at(Index).ForwardOperator){
			case ArcsNeuron::AutoDiffOperator::ANE_NONE:
				return "N/A";	// 該当演算なし
				break;
			case ArcsNeuron::AutoDiffOperator::ANE_ADD:
				return "+";		// 加算
				break;
			case ArcsNeuron::AutoDiffOperator::ANE_MULT:
				return "*";		// 乗算
				break;
			case ArcsNeuron::AutoDiffOperator::ANE_RELU:
				return "ReLU";	// ReLU活性化関数
				break;
			default:
				break;
			}
			return "";
		}

	private:
		ArcsNeuStack(const ArcsNeuStack&) = delete;						//!< コピーコンストラクタ使用禁止
		const ArcsNeuStack& operator=(const ArcsNeuStack&) = delete;	//!< コピー代入演算子使用禁止
		static constexpr size_t MAX_OPERATION = 1024;					//!< 実行する演算子の最大数
		static constexpr size_t MAX_TEMPOBJ = 1024;						//!< 生成される出力エッジ変数用一時オブジェクトの最大数
		std::array<ArcsNeuron::AutoDiffData<T>, MAX_OPERATION> Stack;	//!< 自動微分スタックメモリ(ADSM)
		size_t StackCounter;		//!< 自動微分スタックカウンタ
		std::array<ArcsNeu<T>, MAX_TEMPOBJ> TempObjStack;				//!< 一時オブジェクトスタックメモリ(TOSM)
		size_t TempObjStackCounter;	//!< 一時オブジェクトスタックカウンタ
};

//! @brief ARCS-Neuron 深層学習クラス
//! @tparam	T	深層学習データ型
template <typename T = double>
class ArcsNeu {
	public:
	
		//! @brief 空コンストラクタ
		constexpr ArcsNeu(void) noexcept
			: AutoDiffStack(nullptr), YaddrInStack(nullptr), value(0), grad(0)
		{
			// 初期化以外の処理は無し
		}

		//! @brief コンストラクタ
		constexpr ArcsNeu(ArcsNeuStack<T>* AutoDiff) noexcept
			: AutoDiffStack(AutoDiff), YaddrInStack(nullptr), value(0), grad(0)
		{
			// 初期化以外の処理は無し
		}

		//! @brief コピーコンストラクタ
		//! @param[in]	right	演算子の右側
		constexpr ArcsNeu(const ArcsNeu<T>& right) noexcept
			: AutoDiffStack(right.AutoDiffStack), YaddrInStack(right.YaddrInStack), value(right.value), grad(right.grad)
		{
			// メンバを取り込む以外の処理は無し
		}

		//! @brief ムーブコンストラクタ
		//! @param[in]	right	演算子の右側
		constexpr ArcsNeu(ArcsNeu<T>&& right) noexcept
			: AutoDiffStack(right.AutoDiffStack), YaddrInStack(right.YaddrInStack), value(right.value), grad(right.grad)
		{
			// メンバを取り込む以外の処理は無し
		}

		//! @brief デストラクタ
		~ArcsNeu() noexcept {
			// 特に処理は無し
		}
		
		//! @brief ムーブ代入演算子(左辺値＝右辺値が入力された場合)
		//! @param[in]	right	演算子の右側の一時オブジェクト
		constexpr ArcsNeu& operator=(ArcsNeu<T>&& right) noexcept {
			// メンバを取り込む
			value = right.value;
			grad  = right.grad;
			
			// 出力エッジ変数は左辺値なので一時オブジェクトの永続化は不要
			*(right.YaddrInStack) = this;	// 出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", right.YaddrInStack);

			//printf("ムーブ代入演算子\n");
			return (*this);
		}
		
		//! @brief 代入演算子(左/右辺値＝左/右辺値が入力された場合)
		//! @param[in]	right	演算子の右側
		//! @return 結果
		constexpr ArcsNeu<T>& operator=(ArcsNeu<T>& right) noexcept {	
			// メンバを取り込む
			value = right.value;
			grad  = right.grad;
			
			//printf("左辺値 = 左辺値 or 右辺値 = 右辺値\n");

			return (*this);
		}
		
		//! @brief 代入演算子(定数値の場合)
		//! @param[in]	right	演算子の右側
		//! @return 結果
		constexpr ArcsNeu<T>& operator=(const T& right) noexcept {	
			// メンバに定数値を取り込む
			value = right;
			grad  = 0;
			return (*this);
		}
		
		//! @brief 加算演算子(左辺値＋左辺値が入力された場合)
		//! @param[in]	right	演算子の右側(左辺値)
		//! @return 結果
		constexpr ArcsNeu<T> operator+(ArcsNeu<T>& right) & {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value + right.value;
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_ADD,	// 加算を指定
				.BackOperator = backward_add,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = this,						// 演算子の左側エッジ変数のアドレスを格納
				.u2 = &right					// 演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}

		//! @brief 加算演算子(左辺値＋右辺値が入力された場合)
		//! @param[in]	right	演算子の右側の一時オブジェクト
		//! @return 結果
		constexpr ArcsNeu<T> operator+(ArcsNeu<T>&& right) & {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value + right.value;
			
			// 一時オブジェクトの永続化
			*(right.YaddrInStack) = AutoDiffStack->Persistent(right);	// 前の出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", right.YaddrInStack);

			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_ADD,	// 加算を指定
				.BackOperator = backward_add,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = this,						// 演算子の左側エッジ変数のアドレスを格納
				.u2 = *(right.YaddrInStack)		// 永続化後の演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);
			
			return ret;
		}
		
		//! @brief 加算演算子(右辺値＋左辺値が入力された場合)
		//! @param[in]	right	演算子の右側(左辺値)
		//! @return 結果
		constexpr ArcsNeu<T> operator+(ArcsNeu<T>& right) && {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value + right.value;

			// 一時オブジェクトの永続化
			*(YaddrInStack) = AutoDiffStack->Persistent(*this);	// 前の出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", YaddrInStack);
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_ADD,	// 加算を指定
				.BackOperator = backward_add,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = *(YaddrInStack),			// 永続化後の演算子の左側エッジ変数のアドレスを格納
				.u2 = &right					// 演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}
		
		//! @brief 加算演算子(右辺値＋右辺値が入力された場合)
		//! @param[in]	right	演算子の右側の一時オブジェクト
		//! @return 結果
		constexpr ArcsNeu<T> operator+(ArcsNeu<T>&& right) && {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value + right.value;

			// 一時オブジェクトの永続化
			*(YaddrInStack) = AutoDiffStack->Persistent(*this);			// 前の左出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			*(right.YaddrInStack) = AutoDiffStack->Persistent(right);	// 前の右出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("L YaddrInStack = [%p]\n", YaddrInStack);
			//printf("R YaddrInStack = [%p]\n", right.YaddrInStack);
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_ADD,	// 加算を指定
				.BackOperator = backward_add,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = *(YaddrInStack),			// 永続化後の演算子の左側エッジ変数のアドレスを格納
				.u2 = *(right.YaddrInStack)		// 永続化後の演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}
		
		//! @brief 乗算演算子(左辺値＊左辺値が入力された場合)
		//! @param[in]	right	演算子の右側(左辺値)
		//! @return 結果
		constexpr ArcsNeu<T> operator*(ArcsNeu<T>& right) & {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value*right.value;
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_MULT,	// 乗算を指定
				.BackOperator = backward_mult,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = this,				// 演算子の左側エッジ変数のアドレスを格納
				.u2 = &right			// 演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}

		//! @brief 乗算演算子(左辺値＊右辺値が入力された場合)
		//! @param[in]	right	演算子の右側の一時オブジェクト
		//! @return 結果
		constexpr ArcsNeu<T> operator*(ArcsNeu<T>&& right) & {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value*right.value;
			
			// 一時オブジェクトの永続化
			*(right.YaddrInStack) = AutoDiffStack->Persistent(right);	// 前の出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", right.YaddrInStack);

			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_MULT,	// 乗算を指定
				.BackOperator = backward_mult,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = this,						// 演算子の左側エッジ変数のアドレスを格納
				.u2 = *(right.YaddrInStack)		// 永続化後の演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}
		
		//! @brief 乗算演算子(右辺値＊左辺値が入力された場合)
		//! @param[in]	right	演算子の右側(左辺値)
		//! @return 結果
		constexpr ArcsNeu<T> operator*(ArcsNeu<T>& right) && {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value*right.value;

			// 一時オブジェクトの永続化
			*(YaddrInStack) = AutoDiffStack->Persistent(*this);	// 前の出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", YaddrInStack);
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_MULT,	// 乗算を指定
				.BackOperator = backward_mult,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = *(YaddrInStack),			// 永続化後の演算子の左側エッジ変数のアドレスを格納
				.u2 = &right					// 演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}
		
		//! @brief 乗算演算子(右辺値＊右辺値が入力された場合)
		//! @param[in]	right	演算子の右側の一時オブジェクト
		//! @return 結果
		constexpr ArcsNeu<T> operator*(ArcsNeu<T>&& right) && {
			ArcsNeu<T> ret(AutoDiffStack);
			ret.value = value*right.value;

			// 一時オブジェクトの永続化
			*(YaddrInStack) = AutoDiffStack->Persistent(*this);			// 前の左出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			*(right.YaddrInStack) = AutoDiffStack->Persistent(right);	// 前の右出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("L YaddrInStack = [%p]\n", YaddrInStack);
			//printf("R YaddrInStack = [%p]\n", right.YaddrInStack);
			
			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_MULT,	// 乗算を指定
				.BackOperator = backward_mult,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = *(YaddrInStack),			// 永続化後の演算子の左側エッジ変数のアドレスを格納
				.u2 = *(right.YaddrInStack)		// 永続化後の演算子の右側エッジ変数のアドレスを格納
			};
			ret.YaddrInStack = AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}
		
		//! @brief ReLU活性化関数(左辺値が入力された場合)
		//! @param[in]	input	関数引数(左辺値)
		//! @return	結果
		static constexpr ArcsNeu<T> ReLU(ArcsNeu<T>& input){
			ArcsNeu<T> ret(input.AutoDiffStack);
			ret.value = std::max(static_cast<T>(0), input.value);

			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_RELU,	// ReLUを指定
				.BackOperator = backward_relu,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = &input,					// 活性化関数引数のエッジ変数のアドレスを格納
				.u2 = nullptr					// 未使用
			};
			ret.YaddrInStack = ret.AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);
			
			return ret;
		}

		//! @brief ReLU活性化関数(右辺値が入力された場合)
		//! @param[in]	input	関数引数の一時オブジェクト
		//! @return 結果
		static constexpr ArcsNeu<T> ReLU(ArcsNeu<T>&& input){
			ArcsNeu<T> ret(input.AutoDiffStack);
			ret.value = std::max(static_cast<T>(0), input.value);
			
			// 一時オブジェクトの永続化
			*(input.YaddrInStack) = input.AutoDiffStack->Persistent(input);	// 前の出力エッジ変数のアドレスが確定したので、自動微分スタックに格納
			//printf("YaddrInStack = [%p]\n", input.YaddrInStack);

			// 自動微分スタック
			ArcsNeuron::AutoDiffData<T> ADret = {
				.ForwardOperator = ArcsNeuron::AutoDiffOperator::ANE_RELU,	// ReLUを指定
				.BackOperator = backward_relu,	// 逆方向用演算子への関数オブジェクトを指定
				.u1 = *(input.YaddrInStack),	// 永続化後の活性化関数引数のエッジ変数のアドレスを格納
				.u2 = nullptr					// 未使用
			};
			ret.YaddrInStack = ret.AutoDiffStack->Push(ADret);	// 演算履歴を格納
			// ↑ 演算出力が一時オブジェクトとなり、出力エッジ変数への生ポインタが未確定なので、
			// 　自動微分スタック内の出力エッジ変数への生ポインタのアドレスを一時的に格納
			//printf("Yaddr = %p\n", ret.YaddrInStack);

			return ret;
		}

		//! @brief 自動微分スタック(勾配テープ)への生ポインタを設定する関数
		constexpr void SetAutoDiffStack(ArcsNeuStack<T>* const ADStack){
			AutoDiffStack = ADStack;
		}

		//! @brief 勾配値を設定する関数
		//! @param[in]	GradVal	勾配値
		constexpr void SetGradient(const T& GradVal){
			grad = GradVal;
		}

		//! @brief 勾配値をクリアする関数
		constexpr void ClearGradient(void){
			grad = static_cast<T>(0);
		}

		//! @brief エッジ変数値を表示する関数
		//! @param[in]	VarName	変数名(省略可)
		constexpr void Disp(const std::string& VarName = "") const{
			// データ型によって表示方法を変える
			if constexpr(ArcsNeuron::IsIntFloat<T>){
				printf("%s: val = %g, grad = %g\n", VarName.c_str(), value, grad);
			}
		}

		//! @brief エッジ変数のメモリアドレスを表示する関数
		//! @param[in]	VarName	変数名(省略可)
		constexpr void DispAddress(const std::string& VarName = "") const{
			printf("[%p] %s\n", this, VarName.c_str());		
		}
		
	private:
		ArcsNeuStack<T>* AutoDiffStack;	//! 自動微分スタックへの生ポインタ
		ArcsNeu<T>** YaddrInStack;		//! 自動微分スタック内の出力変数への生ポインタのアドレス
		T value;	//!< エッジ変数の値
		T grad;		//!< エッジ変数の勾配値

		//| @brief 加算演算子の逆
		static constexpr void backward_add(const ArcsNeu<T>* y, ArcsNeu<T>* u1, ArcsNeu<T>* u2){
			(*u1).grad += (*y).grad;	// 加算の勾配はそのまま流すだけ
			(*u2).grad += (*y).grad;	// x + b + x 等の分岐対応のために += で既にセットされた値と加算
		}
		
		//| @brief 乗算演算子の逆
		static constexpr void backward_mult(const ArcsNeu<T>* y, ArcsNeu<T>* u1, ArcsNeu<T>* u2){
			(*u1).grad += (*y).grad * (*u2).value;	// 乗算の勾配は入れ替えて流す
			(*u2).grad += (*y).grad * (*u1).value;	// W*x + W*b 等の分配対応のために += で既にセットされた値と加算
		}

		//| @brief ReLU活性化関数の逆
		static constexpr void backward_relu(const ArcsNeu<T>* y, ArcsNeu<T>* u1, ArcsNeu<T>* u2){
			// ReLUの勾配は正のときのみそのまま流す
			if( 0 <= (*y).grad ){
				(*u1).grad = (*y).grad;
			}else{
				(*u1).grad = 0;
			}
		}
};

// グローバル版関数の定義 (ADL問題を承知で便利さ優先)
namespace ArcsNeuron {

	//! @brief ReLU活性化関数(左辺値が入力された場合)
	//! @tparam	T	エッジ変数のデータ型
	//! @param[in]	input	関数引数(左辺値)
	//! @return	結果
	template<typename T = double>
	constexpr ArcsNeu<T> ReLU(ArcsNeu<T>& input){
		return ArcsNeu<T>::ReLU(input);
	}

	//! @brief ReLU活性化関数(右辺値が入力された場合)
	//! @tparam	T	エッジ変数のデータ型
	//! @param[in]	input	関数引数の一時オブジェクト
	//! @return 結果
	template<typename T = double>
	constexpr ArcsNeu<T> ReLU(ArcsNeu<T>&& input){
		return ArcsNeu<T>::ReLU(std::move(input));	// 左辺値を右辺値にしてから渡す
	}

}

}

#endif

